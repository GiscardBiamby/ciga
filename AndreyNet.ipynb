{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Activation, Add, Conv2D, Flatten, MaxPooling2D, AveragePooling2D\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "from keras.engine.topology import Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS alerts\n",
    "## CHANGE IFNO!  so you dont spam Andrey\n",
    "Can change `account_sid`, `auth_token`, `to` and `from` to info from a FREE twilio account (super easy to set up give you ~2k free sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twilio.rest import Client\n",
    "\n",
    "class DoneAlert(keras.callbacks.Callback):\n",
    "    def on_train_end(self, logs={}):\n",
    "        account_sid = \"ACdb60c905cd24f1bd71e6b49efb7a75c4\"\n",
    "        auth_token = \"607eb22c4134ad6904ce2ad87d066e58\"\n",
    "        to = \"+19258587735\"\n",
    "#         to = \"+15102900156\"\n",
    "        from_ = \"+16504828933\"\n",
    "        client = Client(account_sid, auth_token)\n",
    "        \n",
    "        max_val_acc = max(self.model.history.history['val_acc'])\n",
    "        min_val_loss = min(model.history.history['val_loss'])\n",
    "        msg = \"Training Ended. val_acc=\"+str(max_val_acc)+' \\n min val_loss=' + str(min_val_loss)\n",
    "        message = client.messages.create(to=to, from_=from_, body=msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generators\n",
    "* define image size, 50 seem to work fine\n",
    "* define batch size for which images will be read from the folder\n",
    "* define training and validation data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_data_dir = './datasets/processed/wiki/gender/train/'\n",
    "valid_data_dir = './datasets/processed/wiki/gender/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17512 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(samplewise_center=True,\n",
    "                                   samplewise_std_normalization=True,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "#     save_to_dir='./transformed_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1944 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(samplewise_center=True,\n",
    "                                   samplewise_std_normalization=True)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_data_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num woman: 8756\n",
      "num men: 8756\n"
     ]
    }
   ],
   "source": [
    "num_samples=train_generator.samples\n",
    "num_classes=train_generator.num_classes\n",
    "num_men = sum(train_generator.classes ==1)\n",
    "num_woman = sum(train_generator.classes ==0)\n",
    "print(\"num woman:\", num_woman)\n",
    "print(\"num men:\", num_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of validation samples: 1944\n"
     ]
    }
   ],
   "source": [
    "num_valid=valid_generator.samples\n",
    "print(\"number of validation samples:\", num_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model hyper parameters:\n",
    "Model has stages, each stage with different number of Residual Layers, and different number of filters per layer.\n",
    "#### Define:\n",
    "* number of filters per stage.\n",
    "* number of residual layers per stage, each layer has one residual connection and two (BatchNorm) -> (ReLu) -> (BatchNorm) -> (Relu) -> (Conv2D)\n",
    "* define how many FC layers and their size\n",
    "* define dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of network stages, each stage with different number of filters\n",
    "stage_filters = [32,64, 128]\n",
    "\n",
    "# depth of each stage\n",
    "stage_depth = [2, 3, 2]\n",
    "\n",
    "assert len(stage_filters) == len(stage_depth)\n",
    "\n",
    "num_stages = len(stage_filters)\n",
    "dense_depth = 1\n",
    "dense_size = 512\n",
    "\n",
    "drop_prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=train_generator.image_shape)\n",
    "\n",
    "x = BatchNormalization()(inputs)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(filters=stage_filters[0], kernel_size=7, strides=(2, 2), padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(filters=stage_filters[0], kernel_size=7,  padding='same')(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "\n",
    "res = x\n",
    "for stage in range(num_stages):\n",
    "    filters = stage_filters[stage]\n",
    "    depth = stage_depth[stage]\n",
    "    \n",
    "    # halves residual spatial dimentions to match main branch shape\n",
    "    if stage != 0:\n",
    "        res = Conv2D(filters=filters, kernel_size=(1, 1), strides=2, padding='same')(res)\n",
    "        \n",
    "    for i in range(depth):        \n",
    "        # First resnet layer\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        # halve the spatial dimentions every time number of filters doubles, but not in the first stage\n",
    "        if i == 0 and stage != 0: \n",
    "            x = Conv2D(filters=filters, kernel_size=3, padding='same', strides=(2, 2))(x)\n",
    "        else:\n",
    "            x = Conv2D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        \n",
    "        # Second resnet layer\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        x = Add()([x, res])\n",
    "    \n",
    "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "\n",
    "for _ in range(dense_depth):\n",
    "    x = Dense(dense_size, activation='relu')(x)\n",
    "    x = Dropout(drop_prob)(x)\n",
    "    \n",
    "predictions = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model \n",
    "(writes to file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='./model.png', show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights (if resuming a trainning session)\n",
    "Commented out for convinience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('./weights/Sun_15_Apr_2018_22_41_14.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "* define number of epochs\n",
    "* define callbacks: \n",
    "    * `checkpointer` saves the weights after each epoch, iff validation loss went down.\n",
    "    * `reduce_lr` reduces learning rate if validation loss plareus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='./weights/{}.hdf5'.format(strftime(\"%a_%d_%b_%Y_%H_%M_%S\")), verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.00000001, verbose=1)\n",
    "# tensorboard = TensorBoard(log_dir=\"./logs/{}\".format(strftime(\"%a, %d %b %Y %H:%M:%S\")))\n",
    "sms_alert = DoneAlert()\n",
    "callbacks = [reduce_lr, checkpointer, sms_alert]\n",
    "# callbacks = [reduce_lr, checkpointer]\n",
    "# callbacks = [reduce_lr]\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              validation_data=valid_generator,\n",
    "                              validation_steps=num_valid//batch_size,\n",
    "                              steps_per_epoch=num_samples//batch_size, \n",
    "                              epochs=epochs,\n",
    "                              callbacks=callbacks,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# screwing around area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc, loss, acc, lr = model.history.history.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss, label=\"loss\")\n",
    "plt.plot(val_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(acc, label=\"acc\")\n",
    "plt.plot(val_acc, label=\"val_acc\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(lr, label=\"lr\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
