{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Common \n",
    "import tensorflow\n",
    "import numpy as np\n",
    "\n",
    "# Model Definition \n",
    "import os\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "\n",
    "# Training\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint\n",
    "from time import strftime\n",
    "\n",
    "# Visualizations \n",
    "from keras.utils import plot_model\n",
    "\n",
    "# Image pre-processing\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "color_mode = 'rgb'     # \"grayscale\" or \"rgb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainAndTestSet(image_size, batch_size, color_mode):\n",
    "    train_data_dir = './datasets/equal_data/gender/train/'\n",
    "    valid_data_dir = './datasets/equal_data/gender/valid/'\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale=1.0/255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        color_mode=color_mode,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "    valid_generator = valid_datagen.flow_from_directory(\n",
    "        valid_data_dir,\n",
    "        color_mode=color_mode,\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    num_samples=train_generator.samples\n",
    "    num_classes=train_generator.num_classes\n",
    "    num_men = sum(train_generator.classes == 1)\n",
    "    num_woman = sum(train_generator.classes ==0)\n",
    "    print(\"num woman:\", num_woman)\n",
    "    print(\"num men:\", num_men)\n",
    "    num_valid = valid_generator.samples\n",
    "    \n",
    "    return train_generator, valid_generator, num_valid, num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel_vgg11(image_shape, num_classes, name=\"vgg11\"):\n",
    "    ## VGG16 architecture: https://arxiv.org/pdf/1409.1556.pdf\n",
    "    ## Also may be able to use VGG-Face pre-trained weights. Not sure if the VGG-Face\n",
    "    ## architecture is the same as the VGG-16. \n",
    "    ## Note: if the architectures don't match, they probably only differ by a small \n",
    "    ## amount, so we can probably create a separate VGG-Face model based on our VGG16\n",
    "    ## and then use the weights from Oxford: http://www.robots.ox.ac.uk/~vgg/software/vgg_face/ \n",
    "    \n",
    "    # This implementation is based on Configuration D from page 3 of 1409.1556.pdf, so 16 weight layers total: \n",
    "    \n",
    "    # Input (image): \n",
    "    # Note, I read somewhere that for tensorflow the order matters for performance, \n",
    "    # so check if this should be (1, img_size, img_size) instead? \n",
    "    image_input = Input(shape=image_shape, name=\"image_input\")\n",
    "    \n",
    "    # Note about pre-trained weights: \n",
    "    # We have to do some potentially different pre-processing depending on which \n",
    "    # pre-trained weights we use (if we use any). For example per-pixel mean-centering: \n",
    "    # https://gist.github.com/ksimonyan/211839e770f7b538e2d8#file-readme-md \n",
    "    \n",
    "    # Group 1: \n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g1_01\")(image_input)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"maxpool_g1\")(x)\n",
    "    \n",
    "    # Group 2: \n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g2_01\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"maxpool_g2\")(x)\n",
    "        \n",
    "    # Group 3: \n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g3_01\")(x)\n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g3_02\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"maxpool_g3\")(x)\n",
    "        \n",
    "    # Group 4: \n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g4_01\")(x)\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g4_02\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"maxpool_g4\")(x)\n",
    "        \n",
    "    # Group 5:\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g5_01\")(x)\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g5_02\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"maxpool_g5\")(x)\n",
    "    \n",
    "    # Final weight layers:\n",
    "    # Note: The ReLu and Dropout stages here aren't part of original VGG paper, but the website by the authors\n",
    "    # of the paper lists a slightly different version of the paper model that is their \"best\", which \n",
    "    # includes these layers (http://www.robots.ox.ac.uk/~vgg/research/very_deep/): \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=4096, name=\"final_fc_1\")(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=4096, name=\"final_fc_2\")(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = Dense(units=num_classes, activation='softmax', name='predictions')(x)\n",
    "#     x = Dense(units=1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "    \n",
    "    # VGG paper says \"Finally, to obtain a fixed-size vector of class scores for the image, \n",
    "    # the class score map is spatially averaged (sum-pooled).\"\n",
    "    # Not sure if/where to add that in. \n",
    "    # UDPATE: We probably don't need it. It's not mentioned in their \n",
    "    # website when they define their \"best\" version of their vgg16 and vgg19 architectures. \n",
    "    # x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    model = Model(inputs=image_input, outputs=x, name=name)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel_vgg16(image_shape, num_classes, name=\"vgg16\", weights=\"\"):\n",
    "    ## VGG16 architecture: https://arxiv.org/pdf/1409.1556.pdf\n",
    "    ## Also may be able to use VGG-Face pre-trained weights. Not sure if the VGG-Face\n",
    "    ## architecture is the same as the VGG-16. \n",
    "    ## Note: if the architectures don't match, they probably only differ by a small \n",
    "    ## amount, so we can probably create a separate VGG-Face model based on our VGG16\n",
    "    ## and then use the weights from Oxford: http://www.robots.ox.ac.uk/~vgg/software/vgg_face/ \n",
    "    \n",
    "    # This implementation is based on Configuration D from page 3 of 1409.1556.pdf, so 16 weight layers total: \n",
    "    \n",
    "    # Input (image): \n",
    "    # Note, I read somewhere that for tensorflow the order matters for performance, \n",
    "    # so check if this should be (1, img_size, img_size) instead? \n",
    "    image_input = Input(shape=image_shape, name=\"image_input\")\n",
    "    \n",
    "    # Note about pre-trained weights: \n",
    "    # We have to do some potentially different pre-processing depending on which \n",
    "    # pre-trained weights we use (if we use any). For example per-pixel mean-centering: \n",
    "    # https://gist.github.com/ksimonyan/211839e770f7b538e2d8#file-readme-md \n",
    "    \n",
    "    # Group 1: \n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g1_01\")(image_input)\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g1_02\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"maxpool_g1\")(x)\n",
    "    \n",
    "    # Group 2: \n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g2_01\")(x)\n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g2_02\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"maxpool_g2\")(x)\n",
    "        \n",
    "    # Group 3: \n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g3_01\")(x)\n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g3_02\")(x)\n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g3_03\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"maxpool_g3\")(x)\n",
    "        \n",
    "    # Group 4: \n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g4_01\")(x)\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g4_02\")(x)\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g4_03\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"maxpool_g4\")(x)\n",
    "        \n",
    "    # Group 5:\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g5_01\")(x)\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g5_02\")(x)\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1,1), activation=\"relu\", name=\"conv2d_g5_03\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name=\"maxpool_g5\")(x)\n",
    "    \n",
    "    # Final weight layers:\n",
    "    # Note: The ReLu and Dropout stages here aren't part of original VGG paper, but the website by the authors\n",
    "    # of the paper lists a slightly different version of the paper model that is their \"best\", which \n",
    "    # includes these layers (http://www.robots.ox.ac.uk/~vgg/research/very_deep/): \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=4096, name=\"final_fc_1\")(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=4096, name=\"final_fc_2\")(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    \n",
    "    x = Dense(units=num_classes, activation='softmax', name='predictions')(x)\n",
    "#     x = Dense(units=1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "    \n",
    "    # VGG paper says \"Finally, to obtain a fixed-size vector of class scores for the image, \n",
    "    # the class score map is spatially averaged (sum-pooled).\"\n",
    "    # Not sure if/where to add that in. \n",
    "    # UDPATE: We probably don't need it. It's not mentioned in their \n",
    "    # website when they define their \"best\" version of their vgg16 and vgg19 architectures. \n",
    "    # x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    model = Model(inputs=image_input, outputs=x, name=name)\n",
    "    \n",
    "    if weights != \"\":\n",
    "        weights_dir = \"./weights/\"\n",
    "        weights_path = os.path.join(weights_dir, weights)\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getModel_vgg16(\n",
    "    image_shape = (image_size, image_size, 3) if color_mode==\"rgb\" else (image_size, image_size, 1)\n",
    "    , num_classes = 2\n",
    "#     , weights = \"vgg16\"\n",
    ")\n",
    "\n",
    "# plot_model(model, show_shapes=True, show_layer_names=False)\n",
    "\n",
    "optimizer = optimizers.SGD(lr=1e-2, decay=5e-4, momentum=0.9, nesterov=True)\n",
    "model.compile(\n",
    "    optimizer=optimizer, \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 74\n",
    "model_name = \"vgg16\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17512 images belonging to 2 classes.\n",
      "Found 1944 images belonging to 2 classes.\n",
      "num woman: 8756\n",
      "num men: 8756\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Get Data batches: \n",
    "train_generator, valid_generator, num_valid, num_samples = getTrainAndTestSet(image_size, batch_size, color_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/74\n",
      "273/273 [==============================] - 154s 563ms/step - loss: 0.6933 - acc: 0.5015 - val_loss: 0.6925 - val_acc: 0.5005\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69252, saving model to ./weights/vgg16-Mon_16_Apr_2018_18_53_00.hdf5\n",
      "Epoch 2/74\n",
      "273/273 [==============================] - 147s 540ms/step - loss: 0.6808 - acc: 0.5660 - val_loss: 0.6511 - val_acc: 0.6312\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69252 to 0.65110, saving model to ./weights/vgg16-Mon_16_Apr_2018_18_53_00.hdf5\n",
      "Epoch 3/74\n",
      "273/273 [==============================] - 150s 548ms/step - loss: 0.6416 - acc: 0.6341 - val_loss: 0.6187 - val_acc: 0.6729\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65110 to 0.61873, saving model to ./weights/vgg16-Mon_16_Apr_2018_18_53_00.hdf5\n",
      "Epoch 4/74\n",
      "273/273 [==============================] - 147s 538ms/step - loss: 0.6127 - acc: 0.6704 - val_loss: 0.5543 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61873 to 0.55432, saving model to ./weights/vgg16-Mon_16_Apr_2018_18_53_00.hdf5\n",
      "Epoch 5/74\n",
      "273/273 [==============================] - 152s 557ms/step - loss: 0.5554 - acc: 0.7173 - val_loss: 0.5623 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/74\n",
      "273/273 [==============================] - 150s 549ms/step - loss: 0.4948 - acc: 0.7620 - val_loss: 0.3809 - val_acc: 0.8344\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.55432 to 0.38087, saving model to ./weights/vgg16-Mon_16_Apr_2018_18_53_00.hdf5\n",
      "Epoch 7/74\n",
      "273/273 [==============================] - 150s 549ms/step - loss: 0.3872 - acc: 0.8225 - val_loss: 0.3608 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.38087 to 0.36075, saving model to ./weights/vgg16-Mon_16_Apr_2018_18_53_00.hdf5\n",
      "Epoch 8/74\n",
      "273/273 [==============================] - 148s 542ms/step - loss: 0.3378 - acc: 0.8502 - val_loss: 0.3219 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36075 to 0.32195, saving model to ./weights/vgg16-Mon_16_Apr_2018_18_53_00.hdf5\n",
      "Epoch 9/74\n",
      "273/273 [==============================] - 150s 548ms/step - loss: 0.3040 - acc: 0.8676 - val_loss: 0.2927 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.32195 to 0.29265, saving model to ./weights/vgg16-Mon_16_Apr_2018_18_53_00.hdf5\n",
      "Epoch 10/74\n",
      "273/273 [==============================] - 149s 547ms/step - loss: 0.2805 - acc: 0.8796 - val_loss: 0.2960 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/74\n",
      "273/273 [==============================] - 149s 545ms/step - loss: 0.2584 - acc: 0.8897 - val_loss: 0.2624 - val_acc: 0.8880\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.29265 to 0.26242, saving model to ./weights/vgg16-Mon_16_Apr_2018_18_53_00.hdf5\n",
      "Epoch 12/74\n",
      "273/273 [==============================] - 151s 552ms/step - loss: 0.2380 - acc: 0.9011 - val_loss: 0.2569 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.26242 to 0.25686, saving model to ./weights/vgg16-Mon_16_Apr_2018_18_53_00.hdf5\n",
      "Epoch 13/74\n",
      "273/273 [==============================] - 149s 546ms/step - loss: 0.2279 - acc: 0.9032 - val_loss: 0.2660 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/74\n",
      "273/273 [==============================] - 149s 546ms/step - loss: 0.2164 - acc: 0.9086 - val_loss: 0.2443 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.25686 to 0.24431, saving model to ./weights/vgg16-Mon_16_Apr_2018_18_53_00.hdf5\n",
      "Epoch 15/74\n",
      "273/273 [==============================] - 151s 554ms/step - loss: 0.2052 - acc: 0.9174 - val_loss: 0.2379 - val_acc: 0.9005\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.24431 to 0.23792, saving model to ./weights/vgg16-Mon_16_Apr_2018_18_53_00.hdf5\n",
      "Epoch 16/74\n",
      "273/273 [==============================] - 150s 551ms/step - loss: 0.1964 - acc: 0.9215 - val_loss: 0.2229 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.23792 to 0.22294, saving model to ./weights/vgg16-Mon_16_Apr_2018_18_53_00.hdf5\n",
      "Epoch 17/74\n",
      "273/273 [==============================] - 154s 565ms/step - loss: 0.1864 - acc: 0.9239 - val_loss: 0.2284 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/74\n",
      "148/273 [===============>..............] - ETA: 1:05 - loss: 0.1682 - acc: 0.9361"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-140:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-137:\n",
      "Process ForkPoolWorker-138:\n",
      "Process ForkPoolWorker-139:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 825, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 1246, in _get_batches_of_transformed_samples\n",
      "    x = self.image_data_generator.random_transform(x)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 696, in random_transform\n",
      "    fill_mode=self.fill_mode, cval=self.cval)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 825, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 825, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 1246, in _get_batches_of_transformed_samples\n",
      "    x = self.image_data_generator.random_transform(x)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 239, in apply_transform\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 1246, in _get_batches_of_transformed_samples\n",
      "    x = self.image_data_generator.random_transform(x)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 696, in random_transform\n",
      "    fill_mode=self.fill_mode, cval=self.cval)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 696, in random_transform\n",
      "    fill_mode=self.fill_mode, cval=self.cval)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 239, in <listcomp>\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 825, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 239, in apply_transform\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 1246, in _get_batches_of_transformed_samples\n",
      "    x = self.image_data_generator.random_transform(x)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 486, in affine_transform\n",
      "    output, order, mode, cval, None, None)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 239, in apply_transform\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 239, in <listcomp>\n",
      "    cval=cval) for x_channel in x]\n",
      "KeyboardInterrupt\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 239, in <listcomp>\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 486, in affine_transform\n",
      "    output, order, mode, cval, None, None)\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 486, in affine_transform\n",
      "    output, order, mode, cval, None, None)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 696, in random_transform\n",
      "    fill_mode=self.fill_mode, cval=self.cval)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 239, in apply_transform\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/preprocessing/image.py\", line 239, in <listcomp>\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/home/gbiamby/anaconda3/envs/ciga/lib/python3.6/site-packages/scipy/ndimage/interpolation.py\", line 486, in affine_transform\n",
      "    output, order, mode, cval, None, None)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f17e115fc4c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                               workers=4)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ciga/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ciga/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ciga/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ciga/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ciga/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ciga/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ciga/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##\n",
    "## Train: \n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath = './weights/{}-{}.hdf5'.format(\n",
    "        model_name\n",
    "        , strftime(\"%a_%d_%b_%Y_%H_%M_%S\")\n",
    "    )\n",
    "    , verbose = 1\n",
    "    , save_best_only = True\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.00000001, verbose=1)\n",
    "callbacks = [reduce_lr, checkpointer]\n",
    "# callbacks = [reduce_lr]\n",
    "# early stopping callback \n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              validation_data=valid_generator,\n",
    "                              validation_steps=num_valid//batch_size,\n",
    "                              steps_per_epoch=num_samples//batch_size, \n",
    "                              epochs=num_epochs,\n",
    "                              callbacks=callbacks,\n",
    "                              verbose=1,\n",
    "                              use_multiprocessing=True,\n",
    "                              workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_g1_01 (Conv2D)        (None, 222, 222, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_g1_02 (Conv2D)        (None, 220, 220, 64)      36928     \n",
      "_________________________________________________________________\n",
      "maxpool_g1 (MaxPooling2D)    (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_g2_01 (Conv2D)        (None, 108, 108, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_g2_02 (Conv2D)        (None, 106, 106, 128)     147584    \n",
      "_________________________________________________________________\n",
      "maxpool_g2 (MaxPooling2D)    (None, 53, 53, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_g3_01 (Conv2D)        (None, 51, 51, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_g3_02 (Conv2D)        (None, 49, 49, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_g3_03 (Conv2D)        (None, 47, 47, 256)       590080    \n",
      "_________________________________________________________________\n",
      "maxpool_g3 (MaxPooling2D)    (None, 23, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_g4_01 (Conv2D)        (None, 21, 21, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_g4_02 (Conv2D)        (None, 19, 19, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_g4_03 (Conv2D)        (None, 17, 17, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "maxpool_g4 (MaxPooling2D)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_g5_01 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_g5_02 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_g5_03 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "maxpool_g5 (MaxPooling2D)    (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "final_fc_1 (Dense)           (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "final_fc_2 (Dense)           (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 33,605,442\n",
      "Trainable params: 33,605,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
