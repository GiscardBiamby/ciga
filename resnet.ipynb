{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Activation, Add, Conv2D, Flatten, MaxPooling2D, AveragePooling2D\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS alerts\n",
    "## CHANGE IFNO!  so you dont spam Andrey\n",
    "Can change `account_sid`, `auth_token`, `to` and `from` to info from a FREE twilio account (super easy to set up give you ~2k free sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twilio.rest import Client\n",
    "\n",
    "class DoneAlert(keras.callbacks.Callback):\n",
    "    def on_train_end(self, logs={}):\n",
    "        account_sid = \"ACdb60c905cd24f1bd71e6b49efb7a75c4\"\n",
    "        auth_token = \"607eb22c4134ad6904ce2ad87d066e58\"\n",
    "        to = \"+19258587735\"\n",
    "        from_ = \"+16504828933\"\n",
    "        client = Client(account_sid, auth_token)\n",
    "        \n",
    "        max_val_acc = max(self.model.history.history['val_acc'])\n",
    "        min_val_loss = min(model.history.history['val_loss'])\n",
    "        msg = \"Training Ended. val_acc=\"+str(max_val_acc)+' \\n min val_loss=' + str(min_val_loss)\n",
    "        message = client.messages.create(to=to, from_=from_, body=msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generators\n",
    "* define image size, 50 seem to work fine\n",
    "* define batch size for which images will be read from the folder\n",
    "* define training and validation data location, `proccesse_data` has all images, `proccessed_data_equal_number_of_sam` has equal amount of male and female data points (makes baseline accuracy 0.5, datapoints were discarded randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = 50\n",
    "img_height = 50\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# train_data_dir = './proccessed_data/gender/'\n",
    "train_data_dir = './equal_data/gender/train/'\n",
    "valid_data_dir = './equal_data/gender/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "#     save_to_dir='./transformed_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_data_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=train_generator.samples\n",
    "num_classes=train_generator.num_classes\n",
    "num_men = sum(train_generator.classes ==1)\n",
    "num_woman = sum(train_generator.classes ==0)\n",
    "print(\"num woman:\", num_woman)\n",
    "print(\"num men:\", num_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_valid=valid_generator.samples\n",
    "print(\"number of validation samples:\", num_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model hyper parameters:\n",
    "Model has stages, each stage with different number of Residual Layers, and different number of filters per layer.\n",
    "#### Define:\n",
    "* number of filters per stage.\n",
    "* number of residual layers per stage, each layer has one residual connection and two (BatchNorm) -> (ReLu) -> (BatchNorm) -> (Relu) -> (Conv2D)\n",
    "* define how many FC layers and their size\n",
    "* define dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of network stages, each stage with different number of filters\n",
    "stage_filters = [16, 32]\n",
    "\n",
    "# depth of each stage\n",
    "stage_depth = [2, 3]\n",
    "\n",
    "assert len(stage_filters) == len(stage_depth)\n",
    "\n",
    "num_stages = len(stage_filters)\n",
    "dense_depth = 1\n",
    "dense_size = 256\n",
    "\n",
    "drop_prob = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=train_generator.image_shape)\n",
    "\n",
    "x = BatchNormalization()(inputs)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(filters=stage_filters[0], kernel_size=7)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(filters=stage_filters[0], kernel_size=7)(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2), strides=None)(x)\n",
    "\n",
    "for stage in range(num_stages):\n",
    "    filters = stage_filters[stage]\n",
    "    depth = stage_depth[stage]\n",
    "    # change residual from previouse stage to current size\n",
    "    if 0 < stage: \n",
    "        # FIXME: does the 1x1 conv on the main branch, need to check if doing it only on residual is better\n",
    "        x = Conv2D(filters=filters, kernel_size=(1, 1))(x) \n",
    "    for _ in range(depth-1):\n",
    "        res = x\n",
    "        # First resnet layer\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        \n",
    "        # Second resnet layer\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        x = Add()([x, res])\n",
    "        \n",
    "        x = Dropout(drop_prob)(x)\n",
    "    \n",
    "        \n",
    "x = AveragePooling2D(pool_size=(2, 2), strides=None)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "for _ in range(dense_depth):\n",
    "    x = Dense(dense_size, activation='relu')(x)\n",
    "    \n",
    "predictions = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights (if resuming a trainning session)\n",
    "Commented out for convinience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights('./weights/Sat_07_Apr_2018_20_53_48.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "* define number of epochs\n",
    "* define callbacks: \n",
    "    * `checkpointer` saves the weights after each epoch, iff validation loss went down.\n",
    "    * `reduce_lr` reduces learning rate if validation loss plareus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='./weights/{}.hdf5'.format(strftime(\"%a_%d_%b_%Y_%H_%M_%S\")), verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0000001, verbose=1)\n",
    "# tensorboard = TensorBoard(log_dir=\"./logs/{}\".format(strftime(\"%a, %d %b %Y %H:%M:%S\")))\n",
    "sms_alert = DoneAlert()\n",
    "# callbacks = [reduce_lr, checkpointer, sms_alert]\n",
    "# callbacks = [reduce_lr, checkpointer]\n",
    "callbacks = [reduce_lr]\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              validation_data=valid_generator,\n",
    "                              validation_steps=num_valid//batch_size,\n",
    "                              steps_per_epoch=num_samples//batch_size, \n",
    "                              epochs=epochs,\n",
    "                              callbacks=callbacks,\n",
    "                              verbose=1,\n",
    "                              use_multiprocessing=True,\n",
    "                              workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model \n",
    "(writes to file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# screwing around area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss, label=\"loss\")\n",
    "plt.plot(val_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(acc, label=\"acc\")\n",
    "plt.plot(val_acc, label=\"val_acc\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(lr, label=\"lr\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
