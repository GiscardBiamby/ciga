{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrey/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import strftime\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Activation, Add, Conv2D, Flatten, MaxPooling2D, AveragePooling2D\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "from keras.engine.topology import Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS alerts\n",
    "## CHANGE IFNO!  so you dont spam Andrey\n",
    "Can change `account_sid`, `auth_token`, `to` and `from` to info from a FREE twilio account (super easy to set up give you ~2k free sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twilio.rest import Client\n",
    "\n",
    "class DoneAlert(keras.callbacks.Callback):\n",
    "    def on_train_end(self, logs={}):\n",
    "        account_sid = \"ACdb60c905cd24f1bd71e6b49efb7a75c4\"\n",
    "        auth_token = \"607eb22c4134ad6904ce2ad87d066e58\"\n",
    "        to = \"+19258587735\"\n",
    "#         to = \"+15102900156\"\n",
    "        from_ = \"+16504828933\"\n",
    "        client = Client(account_sid, auth_token)\n",
    "        \n",
    "        max_val_acc = max(self.model.history.history['val_acc'])\n",
    "        min_val_loss = min(model.history.history['val_loss'])\n",
    "        msg = \"Training Ended. val_acc=\"+str(max_val_acc)+' \\n min val_loss=' + str(min_val_loss)\n",
    "        message = client.messages.create(to=to, from_=from_, body=msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generators\n",
    "* define image size, 50 seem to work fine\n",
    "* define batch size for which images will be read from the folder\n",
    "* define training and validation data location, `proccesse_data` has all images, `proccessed_data_equal_number_of_sam` has equal amount of male and female data points (makes baseline accuracy 0.5, datapoints were discarded randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 100\n",
    "img_height = 100\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# train_data_dir = './proccessed_data/gender/'\n",
    "# Should these be put into ./datasets/processed/equal_data/...? \n",
    "train_data_dir = './datasets/equal_data/gender/train/'\n",
    "valid_data_dir = './datasets/equal_data/gender/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17512 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "#     save_to_dir='./transformed_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1944 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_data_dir,\n",
    "    color_mode='grayscale',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num woman: 8756\n",
      "num men: 8756\n"
     ]
    }
   ],
   "source": [
    "num_samples=train_generator.samples\n",
    "num_classes=train_generator.num_classes\n",
    "num_men = sum(train_generator.classes ==1)\n",
    "num_woman = sum(train_generator.classes ==0)\n",
    "print(\"num woman:\", num_woman)\n",
    "print(\"num men:\", num_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of validation samples: 1944\n"
     ]
    }
   ],
   "source": [
    "num_valid=valid_generator.samples\n",
    "print(\"number of validation samples:\", num_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model hyper parameters:\n",
    "Model has stages, each stage with different number of Residual Layers, and different number of filters per layer.\n",
    "#### Define:\n",
    "* number of filters per stage.\n",
    "* number of residual layers per stage, each layer has one residual connection and two (BatchNorm) -> (ReLu) -> (BatchNorm) -> (Relu) -> (Conv2D)\n",
    "* define how many FC layers and their size\n",
    "* define dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of network stages, each stage with different number of filters\n",
    "stage_filters = [1]\n",
    "\n",
    "# depth of each stage\n",
    "stage_depth = [1]\n",
    "\n",
    "assert len(stage_filters) == len(stage_depth)\n",
    "\n",
    "num_stages = len(stage_filters)\n",
    "dense_depth = 1\n",
    "dense_size = 256\n",
    "\n",
    "drop_prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=train_generator.image_shape)\n",
    "\n",
    "x = BatchNormalization()(inputs)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(filters=stage_filters[0], kernel_size=7)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(filters=stage_filters[0], kernel_size=7)(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2,2))(x)\n",
    "res = x\n",
    "for stage in range(num_stages):\n",
    "    filters = stage_filters[stage]\n",
    "    depth = stage_depth[stage]\n",
    "    \n",
    "     # change residual from previouse stage to current size\n",
    "    if stage != 0:    \n",
    "        res = Conv2D(filters=filters, kernel_size=(1, 1))(res)\n",
    "        \n",
    "    for i in range(depth):        \n",
    "        # First resnet layer\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        \n",
    "\n",
    "        \n",
    "        # Second resnet layer\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters=filters, kernel_size=3, padding='same')(x)\n",
    "        x = Add()([x, res])\n",
    "        res = x\n",
    "\n",
    "        \n",
    "x = AveragePooling2D(pool_size=(2, 2), strides=None)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(drop_prob)(x)\n",
    "\n",
    "for _ in range(dense_depth):\n",
    "    x = Dense(dense_size, activation='relu')(x)\n",
    "    \n",
    "predictions = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model \n",
    "(writes to file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='./model.png', show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights (if resuming a trainning session)\n",
    "Commented out for convinience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('./weights/Sat_14_Apr_2018_19_14_37.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "* define number of epochs\n",
    "* define callbacks: \n",
    "    * `checkpointer` saves the weights after each epoch, iff validation loss went down.\n",
    "    * `reduce_lr` reduces learning rate if validation loss plareus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "547/547 [==============================] - 418s 764ms/step - loss: 0.6497 - acc: 0.6223 - val_loss: 0.6001 - val_acc: 0.6771\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60015, saving model to ./weights/Sun_15_Apr_2018_18_22_45.hdf5\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='./weights/{}.hdf5'.format(strftime(\"%a_%d_%b_%Y_%H_%M_%S\")), verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.00000001, verbose=1)\n",
    "# tensorboard = TensorBoard(log_dir=\"./logs/{}\".format(strftime(\"%a, %d %b %Y %H:%M:%S\")))\n",
    "sms_alert = DoneAlert()\n",
    "# callbacks = [reduce_lr, checkpointer, sms_alert]\n",
    "callbacks = [reduce_lr, checkpointer]\n",
    "# callbacks = [reduce_lr]\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              validation_data=valid_generator,\n",
    "                              validation_steps=num_valid//batch_size,\n",
    "                              steps_per_epoch=num_samples//batch_size, \n",
    "                              epochs=epochs,\n",
    "                              callbacks=callbacks,\n",
    "                              verbose=1,\n",
    "                              use_multiprocessing=True,\n",
    "                              workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# screwing around area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc, loss, acc, lr = model.history.history.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss, label=\"loss\")\n",
    "plt.plot(val_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(acc, label=\"acc\")\n",
    "plt.plot(val_acc, label=\"val_acc\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(lr, label=\"lr\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 60, 60, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 60, 60, 1)    4           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 60, 60, 1)    0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 54, 54, 4)    200         activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 54, 54, 4)    16          conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 54, 54, 4)    0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 48, 48, 4)    788         activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 23, 23, 4)    0           conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 23, 23, 4)    16          max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 23, 23, 4)    0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 23, 23, 4)    148         activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 23, 23, 4)    16          conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 23, 23, 4)    0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 23, 23, 4)    148         activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 23, 23, 4)    16          conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 23, 23, 4)    0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 23, 23, 4)    148         activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 23, 23, 4)    16          conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 23, 23, 4)    0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 23, 23, 4)    148         activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 23, 23, 4)    0           conv2d_236[0][0]                 \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 12, 12, 6)    30          add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 12, 12, 6)    0           conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 12, 12, 6)    24          activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 12, 12, 6)    0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 12, 12, 6)    330         activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 12, 12, 6)    24          conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 12, 12, 6)    0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 12, 12, 6)    330         activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 12, 12, 6)    24          conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 12, 12, 6)    0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 12, 12, 6)    330         activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 12, 12, 6)    24          conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 12, 12, 6)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 12, 12, 6)    330         activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 12, 12, 6)    30          add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 12, 12, 6)    0           conv2d_242[0][0]                 \n",
      "                                                                 conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 12, 12, 6)    24          add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 12, 12, 6)    0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 12, 12, 6)    330         activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 12, 12, 6)    24          conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 12, 12, 6)    0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 12, 12, 6)    330         activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 12, 12, 6)    24          conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 12, 12, 6)    0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 12, 12, 6)    330         activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 12, 12, 6)    24          conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 12, 12, 6)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 12, 12, 6)    330         activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 12, 12, 6)    0           conv2d_246[0][0]                 \n",
      "                                                                 add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 6, 6, 8)      56          add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 6, 6, 8)      0           conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 6, 6, 8)      32          activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 6, 6, 8)      0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 6, 6, 8)      584         activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 6, 6, 8)      32          conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 6, 6, 8)      0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 6, 6, 8)      584         activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 6, 6, 8)      32          conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 6, 6, 8)      0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 6, 6, 8)      584         activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 6, 6, 8)      32          conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 6, 6, 8)      0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 6, 6, 8)      584         activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 6, 6, 8)      56          add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 6, 6, 8)      0           conv2d_252[0][0]                 \n",
      "                                                                 conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 6, 6, 8)      32          add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 6, 6, 8)      0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 6, 6, 8)      584         activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 6, 6, 8)      32          conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 6, 6, 8)      0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 6, 6, 8)      584         activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 6, 6, 8)      32          conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 6, 6, 8)      0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 6, 6, 8)      584         activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 6, 6, 8)      32          conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 6, 6, 8)      0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 6, 6, 8)      584         activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 6, 6, 8)      0           conv2d_256[0][0]                 \n",
      "                                                                 add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 3, 3, 10)     90          add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 3, 3, 10)     0           conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 3, 3, 10)     40          activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 3, 3, 10)     0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 3, 3, 10)     910         activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 3, 3, 10)     40          conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 3, 3, 10)     0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 3, 3, 10)     910         activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 3, 3, 10)     40          conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 3, 3, 10)     0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 3, 3, 10)     910         activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 3, 3, 10)     40          conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 3, 3, 10)     0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 3, 3, 10)     910         activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 3, 3, 10)     90          add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 3, 3, 10)     0           conv2d_262[0][0]                 \n",
      "                                                                 conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 2, 2, 12)     132         add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 2, 2, 12)     0           conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 2, 2, 12)     48          activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 2, 2, 12)     0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 2, 2, 12)     1308        activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 2, 2, 12)     48          conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 2, 2, 12)     0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 2, 2, 12)     1308        activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 2, 2, 12)     48          conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 2, 2, 12)     0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 2, 2, 12)     1308        activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 2, 2, 12)     48          conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 2, 2, 12)     0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 2, 2, 12)     1308        activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 2, 2, 12)     132         add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 2, 2, 12)     0           conv2d_268[0][0]                 \n",
      "                                                                 conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 1, 1, 12)     0           add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 12)           0           average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 12)           0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          3328        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            257         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,849\n",
      "Trainable params: 22,407\n",
      "Non-trainable params: 442\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
